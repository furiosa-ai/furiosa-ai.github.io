.. _Roadmap:

==================================================
Roadmap
==================================================

FurisaAI strives to deliver the releases for each month, while offering patch releases.
This page shows the forward-looking roadmap of ongoing & upcoming projects
and when they are expected to land, broken down by areas on :ref:`our software stack <SoftwareStack>`.

**************************************
Latest Recent Release
**************************************

The latest release is 2024.2.1 (beta 0) on Jan 10, 2025.
You can find the release notes :ref:`here <WhatsNew>`.

**************************************
Future Releases
**************************************


2025 Q1
==========================================
* ðŸ”² Tensor Parallelism support Phase 2: Inter-chip (planned for 2025.1.0 release)
* ðŸ”² Speculating with a draft model (planned for 2025.1.0 release)
* ðŸ”² CPU memory swapping of KV cache in Furiosa LLM (planned for 2025.2.0 release)
* ðŸ”² ``torch.compile()`` backend (planned for 2025.2.0 release)
* ðŸ”² Embedding API support in Furiosa LLM (planned for 2025.1.0 release)
* ðŸ”² Tool-calling support in Furiosa LLM (planned for 2025.1.0 release)
* ðŸ”² Chunked Prefill support in Furiosa LLM (planned for 2025.2.0 release)


2024 Q4
==========================================
* âœ… Language Model Support: CodeLLaMA2, Vicuna, Solar, EXAONE-3.0 (2024.2.0 release)
* âœ… Vision Model Support: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, .. (2024.2.0 release)
* âœ… Tensor Parallelism support Phase 1: Intra-chip (2024.2.0 release)
* âœ… Torch 2.4.1 support (2024.2.0)
* âœ… Huggingface Optimum integration (2024.2.0 release)
* ðŸ”² Device remapping support (e.g., /dev/rngd/npu2pe0-3 -> /dev/rngd/npu0pe0-3) for container (planned 2024.2.2 release)
* ðŸ”² CPU memory swapping of KV cache in Furiosa LLM (postponed to 2025 Q1)
* ðŸ”² Speculating with a draft model (postponed to 2025 Q1)
* ðŸ”² ``torch.compile()`` backend (postponed to 2025 Q1)
