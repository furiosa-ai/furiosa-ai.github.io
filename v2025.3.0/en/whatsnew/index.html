
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-0HTTHGM3MD"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-0HTTHGM3MD');
    </script>
    
    <title>What’s New &#8212; FuriosaAI Developer Center 2025.3.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=37f7f57c" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=c5ef0929"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'whatsnew/index';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://raw.githubusercontent.com/furiosa-ai/furiosa-ai.github.io/refs/heads/main/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '2025.3.0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            true;
        </script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Roadmap" href="../overview/roadmap.html" />
    <link rel="prev" title="Supported Models" href="../overview/supported_models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="2025.3.0" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/doc-logo-dark.svg" class="logo__image only-light" alt=""/>
    <img src="../_static/doc-logo-light.svg" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">
            <div class='sidebar-title mr-auto'>
                Furiosa Docs
            </div>
        </p>
  
</a></div>
        <div class="sidebar-primary-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../overview/rngd.html">FuriosaAI RNGD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/software_stack.html">FuriosaAI’s Software Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/supported_models.html">Supported Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">What’s New</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/roadmap.html">Roadmap</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/prerequisites.html">Installing Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/furiosa_llm.html">Quick Start with Furiosa-LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/upgrade_guide.html">Upgrading FuriosaAI’s Software</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Furiosa-LLM</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../furiosa_llm/intro.html">Furiosa-LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html">OpenAI-Compatible Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../furiosa_llm/model-preparation.html">Model Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../furiosa_llm/build-artifacts-by-examples.html">Building Model Artifacts By Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../furiosa_llm/model-parallelism.html">Model Parallelism</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../furiosa_llm/reference.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../furiosa_llm/reference/llm.html">LLM class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../furiosa_llm/reference/sampling_params.html">SamplingParams class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../furiosa_llm/reference/artifact_builder.html">ArtifactBuilder</a></li>


<li class="toctree-l2"><a class="reference internal" href="../furiosa_llm/reference/llm_engine.html">LLMEngine class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../furiosa_llm/reference/async_llm_engine.html">AsyncLLMEngine class</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../furiosa_llm/examples.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../furiosa_llm/examples/llm_chat.html">Chat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../furiosa_llm/examples/llm_chat_with_tools.html">Chat with tools</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../furiosa_llm/k8s_deployment.html">Deploying Furiosa-LLM on Kubernetes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cloud Native Toolkit</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cloud_native_toolkit/intro.html">Cloud Native Toolkit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cloud_native_toolkit/container.html">Container Support</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cloud_native_toolkit/kubernetes.html">Kubernetes Plugins</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cloud_native_toolkit/kubernetes/feature_discovery.html">Installing Furiosa Feature Discovery</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud_native_toolkit/kubernetes/device_plugin.html">Installing Furiosa Device Plugin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud_native_toolkit/kubernetes/metrics_exporter.html">Installing Furiosa Metrics Exporter</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Device Management</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../device_management/system_management_interface.html">Furiosa SMI</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../device_management/system_management_interface/furiosa_smi_cli.html">Furiosa SMI CLI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../device_management/system_management_interface/furiosa_smi_lib.html">Furiosa SMI Library</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials and Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://github.com/furiosa-ai/sdk-cookbook">FuriosaAI SDK CookBook</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Customer Support</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://forums.furiosa.ai">Forums</a></li>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.atlassian.net/servicedesk/customer/portals/">Customer Support</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://furiosa.ai">FuriosaAI Homepage</a></li>
<li class="toctree-l1"><a class="reference external" href="https://furiosa-ai.github.io/docs/latest/en/">Furiosa Gen 1 NPU SDK Doc</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item"><img id='furiosa_logo' width="100" /></div>
      <div class="sidebar-primary-item">

  <p class="copyright">
    
      © Copyright 2025 FuriosaAI Inc.
      <br/>
    
  </p>
</div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button></div>
      
        <div class="header-article-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="header-article-item"><button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>What’s New</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2>  </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2025-3-0-beta3-2025-08-04">Furiosa SDK 2025.3.0 Beta3 (2025-08-04)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#highlights">🚀 Highlights</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#major-features-improvements">Major Features &amp; Improvements</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-highlights">Performance Highlights</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#expanded-model-support">Expanded Model Support</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#breaking-changes">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2025-2-0-beta2-2025-04-25">Furiosa SDK 2025.2.0 Beta2 (2025-04-25)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2025-2-0-highlights">🚀 Highlights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2025-1-0-beta1-2025-02-24">Furiosa SDK 2025.1.0 Beta1 (2025-02-24)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2025-1-0-highlights">🚀 Highlights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deprecations-upcoming-changes">⚠️ Deprecations &amp; Upcoming Changes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2024-2-1-beta0-2025-01-10">Furiosa SDK 2024.2.1 Beta0 (2025-01-10)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2024-2-1-highlights">🚀 Highlights</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2024-2-0-beta0-2024-12-23">Furiosa SDK 2024.2.0 Beta0 (2024-12-23)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2024-2-0-highlights">🚀 Highlights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2024-1-0-alpha-2024-10-11">Furiosa SDK 2024.1.0 Alpha (2024-10-11)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2024-1-0-highlights">🚀 Highlights</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="what-s-new">
<span id="whatsnew"></span><h1>What’s New<a class="headerlink" href="#what-s-new" title="Link to this heading">#</a></h1>
<nav class="contents local" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#furiosa-sdk-2025-3-0-beta3-2025-08-04" id="id13">Furiosa SDK 2025.3.0 Beta3 (2025-08-04)</a></p></li>
<li><p><a class="reference internal" href="#furiosa-sdk-2025-2-0-beta2-2025-04-25" id="id14">Furiosa SDK 2025.2.0 Beta2 (2025-04-25)</a></p></li>
<li><p><a class="reference internal" href="#furiosa-sdk-2025-1-0-beta1-2025-02-24" id="id15">Furiosa SDK 2025.1.0 Beta1 (2025-02-24)</a></p></li>
<li><p><a class="reference internal" href="#furiosa-sdk-2024-2-1-beta0-2025-01-10" id="id16">Furiosa SDK 2024.2.1 Beta0 (2025-01-10)</a></p></li>
<li><p><a class="reference internal" href="#furiosa-sdk-2024-2-0-beta0-2024-12-23" id="id17">Furiosa SDK 2024.2.0 Beta0 (2024-12-23)</a></p></li>
<li><p><a class="reference internal" href="#furiosa-sdk-2024-1-0-alpha-2024-10-11" id="id18">Furiosa SDK 2024.1.0 Alpha (2024-10-11)</a></p></li>
</ul>
</nav>
<section id="furiosa-sdk-2025-3-0-beta3-2025-08-04">
<span id="release2025-3-0"></span><h2>Furiosa SDK 2025.3.0 Beta3 (2025-08-04)<a class="headerlink" href="#furiosa-sdk-2025-3-0-beta3-2025-08-04" title="Link to this heading">#</a></h2>
<p>The 2025.3.0 release primarily focuses on inter-chip tensor parallelism and performance optimizations.
The efforts have resulted in dramatic performance improvements, including up to 3x throughput increase
for Llama 3.1 70B and up to 55% reduction in first-token latency for Llama 3.1 8B.
This release also introduces support for the Qwen 2 and 2.5 models, as well as W8A16 quantization.</p>
<p>Please refer to the <a class="reference internal" href="../get_started/upgrade_guide.html#upgradeguide"><span class="std std-ref">Upgrading FuriosaAI’s Software</span></a> section for instructions on
obtaining this update.</p>
<section id="highlights">
<span id="release2025-3-0-highlights"></span><h3>🚀 Highlights<a class="headerlink" href="#highlights" title="Link to this heading">#</a></h3>
<section id="major-features-improvements">
<h4>Major Features &amp; Improvements<a class="headerlink" href="#major-features-improvements" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Inter-chip Tensor Parallelism</p>
<ul>
<li><p>Tensor parallelism across multiple NPU cards is now officially supported, enabling efficient
scaling of large models and leading to significantly improved throughput.</p></li>
<li><p>To maximize performance, this feature is backed by key optimizations including:
optimized PCIe paths for peer-to-peer (P2P) communication, advanced communication scheduling,
and compiler tactics that overlap inter-chip DMA with computation.</p></li>
</ul>
</li>
<li><p>Compiler and Runtime Optimizations</p>
<ul>
<li><p>Enhanced Global Compiler Optimization: Furiosa compiler’s global optimization
capabilities were enhanced to maximize SRAM reuse between transformer blocks.
This reduces memory access latency and boosts overall throughput.</p></li>
<li><p>Runtime Optimization: Further optimized the runtime by reducing interference
between the host and NPU, improving synchronization across devices, and
minimizing overhead between consecutive decoding steps.</p></li>
</ul>
</li>
</ul>
</section>
<section id="performance-highlights">
<h4>Performance Highlights<a class="headerlink" href="#performance-highlights" title="Link to this heading">#</a></h4>
<p>The optimizations in this release yield the following performance improvements compared
to the previous release 2025.2:</p>
<ul class="simple">
<li><p>Llama 3.1 8B: Up to 4.5% average throughput improvement and up to a 55% average reduction in
Time-to-First-Token (TTFT).</p></li>
<li><p>Llama 3.1 70B: Up to 3x average throughput improvement and up to a 35% average reduction in
Time-to-First-Token (TTFT).</p></li>
</ul>
</section>
<section id="expanded-model-support">
<h4>Expanded Model Support<a class="headerlink" href="#expanded-model-support" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>New Model Families: Added support for Qwen 2 and 2.5 models
(e.g., <a class="reference external" href="https://huggingface.co/furiosa-ai/Qwen2.5-Coder-32B-Instruct">Qwen2.5-Coder-32B-Instruct</a>).</p></li>
<li><p>New Quantization Support: Added support for W8A16 quantization
(e.g., <a class="reference external" href="https://huggingface.co/furiosa-ai/Llama-3.3-70B-Instruct-INT8">Llama-3.3-70B-Instruct-INT8</a>).</p></li>
<li><p>New pre-compiled artifacts are available on the Hugging Face Hub:
* <a class="reference external" href="https://huggingface.co/furiosa-ai/EXAONE-3.5-32B-Instruct">EXAONE-3.5-32B-Instruct</a>
* <a class="reference external" href="https://huggingface.co/furiosa-ai/DeepSeek-R1-Distill-Llama-70B">DeepSeek-R1-Distill-Llama-70B</a>
* <a class="reference external" href="https://huggingface.co/furiosa-ai/Llama-3.3-70B-Instruct">Llama-3.3-70B-Instruct</a>
* <a class="reference external" href="https://huggingface.co/furiosa-ai/Llama-3.3-70B-Instruct-INT8">Llama-3.3-70B-Instruct-INT8</a>
* <a class="reference external" href="https://huggingface.co/furiosa-ai/Qwen-2.5-Coder-32B">Qwen-2.5-Coder-32B</a></p></li>
<li><p>Longer Context Lengths: all pre-compiled artifacts on Hugging Face Hub now support
context lengths of up to 32k tokens.</p></li>
</ul>
</section>
</section>
<section id="breaking-changes">
<h3>🚨 Breaking Changes<a class="headerlink" href="#breaking-changes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The SDK 2025.2.0 cannot load artifacts built with 2025.3.x.
Please use the artifact built with 2025.3.x, or rebuild the model again with the new SDK.</p></li>
<li><p>furiosa-mlperf is deprecated and is removed from this release.
Please use other benchmark tools, such as <a class="reference external" href="https://github.com/vllm-project/vllm/tree/main/benchmarks">vLLM benchmark</a>
or <a class="reference external" href="https://github.com/ray-project/llmperf">LLMPerf</a>.</p></li>
</ul>
</section>
</section>
<section id="furiosa-sdk-2025-2-0-beta2-2025-04-25">
<span id="release2025-2-0"></span><h2>Furiosa SDK 2025.2.0 Beta2 (2025-04-25)<a class="headerlink" href="#furiosa-sdk-2025-2-0-beta2-2025-04-25" title="Link to this heading">#</a></h2>
<p>RNGD SDK 2025.2.0 is the fourth major release, bringing a wide range of new features and significant improvements,
including support for reasoning models, the metrics endpoint, the chat API, the Hugging Face Hub, the abort() API,
and the chunked prefill feature. This release also enables direct building of bfloat16, float16, and float32 models from
the Hugging Face Hub without a quantization step. Additionally, pre-compiled model artifacts are now available
on the Hugging Face Hub, so you can use them immediately without having to build them yourself.</p>
<p>Please refer to the <a class="reference internal" href="../get_started/upgrade_guide.html#upgradeguide"><span class="std std-ref">Upgrading FuriosaAI’s Software</span></a> section for instructions on
obtaining this update.</p>
<section id="release2025-2-0-highlights">
<span id="id2"></span><h3>🚀 Highlights<a class="headerlink" href="#release2025-2-0-highlights" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Add support for <a class="reference external" href="https://community.openai.com/t/usage-stats-now-available-when-using-streaming-with-the-chat-completions-api-or-completions-api/738156">stream_options.include_usage</a> in <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#openaiserver"><span class="std std-ref">OpenAI-Compatible Server</span></a>.</p></li>
<li><p>Introduce <code class="docutils literal notranslate"><span class="pre">LLM.chat()</span></code> API to support chat-based models (see <a class="reference internal" href="../furiosa_llm/examples/llm_chat.html#furiosallmexampleschat"><span class="std std-ref">Chat</span></a>, <a class="reference internal" href="../furiosa_llm/examples/llm_chat_with_tools.html#furiosallmexampleschatwithtools"><span class="std std-ref">Chat with tools</span></a>).</p></li>
<li><p>Mitigate out-of-memory issue by setting the default value of <code class="docutils literal notranslate"><span class="pre">spare_block_ratio=0</span></code> in <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#openaiserver"><span class="std std-ref">OpenAI-Compatible Server</span></a>.</p></li>
<li><p>Fix a bug caused by duplicate buckets in <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span></code>.</p></li>
<li><p>Add support for <code class="docutils literal notranslate"><span class="pre">/v1/models</span></code> and <code class="docutils literal notranslate"><span class="pre">/v1/models/{model_id}</span></code> endpoints in <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span></code> (see <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#modelsendpoint"><span class="std std-ref">Models Endpoint</span></a>).</p></li>
<li><p>Add support for <code class="docutils literal notranslate"><span class="pre">/version</span></code> endpoint in <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#openaiserver"><span class="std std-ref">OpenAI-Compatible Server</span></a> (see <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#versionendpoint"><span class="std std-ref">Version Endpoint</span></a>).</p></li>
<li><p>Fix a bug that prevented interruption of a running <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#openaiserver"><span class="std std-ref">OpenAI-Compatible Server</span></a>. by <code class="docutils literal notranslate"><span class="pre">Ctrl+C</span></code>.</p></li>
<li><p>Add support the chunked prefill feature in <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span></code> (see <a class="reference internal" href="../furiosa_llm/build-artifacts-by-examples.html#chunkedprefill"><span class="std std-ref">Long-context Length and Chunked Prefill</span></a>).</p></li>
<li><p>Enable direct building of bfloat16/float16/float32 models without quantization step (see <a class="reference internal" href="../furiosa_llm/build-artifacts-by-examples.html#autobfloat16cast"><span class="std std-ref">Building Float16, Float32 Models</span></a>).</p></li>
<li><p>Add support for the reasoning model parser in <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#openaiserver"><span class="std std-ref">OpenAI-Compatible Server</span></a> (see <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#reasoning"><span class="std std-ref">Reasoning Support</span></a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LLM</span></code> API, <code class="docutils literal notranslate"><span class="pre">furiosa-mlperf</span></code>, <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">serve</span></code> now support loading artifacts from Hugging Face Hub.</p></li>
<li><p>Add support for <code class="docutils literal notranslate"><span class="pre">npu_queue_limit</span></code> option in <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">serve</span></code> command to configure the NPU queue limit.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">furiosa-llm</span></code> now supports Python 3.11 and 3.12.</p></li>
<li><p>Optimize the NPU DRAM stack usage for the <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span></code>.</p></li>
<li><p>Support Ubuntu 24.04 (Noble Numbat).</p></li>
<li><p>Remove the group <code class="docutils literal notranslate"><span class="pre">furiosa</span></code> to access NPU devices on Linux system.</p></li>
<li><p>Pre-compiled model artifacts are now available in Hugging Face Hub.</p></li>
<li><p>Add support for <code class="docutils literal notranslate"><span class="pre">abort()</span></code> in <code class="docutils literal notranslate"><span class="pre">LLMEngine</span></code> and <code class="docutils literal notranslate"><span class="pre">AsyncLLMEngine</span></code> APIs.</p></li>
<li><p>Add support for the metrics endpoint (<code class="docutils literal notranslate"><span class="pre">/metrics</span></code>) used to monitor the health of <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#openaiserver"><span class="std std-ref">OpenAI-Compatible Server</span></a> (see <a class="reference internal" href="../furiosa_llm/furiosa-llm-serve.html#metricsendpoint"><span class="std std-ref">Metrics Endpoint</span></a>).</p></li>
<li><p>Support sampling parameter “logprobs” in Furiosa-LLM (see <a class="reference internal" href="../furiosa_llm/reference/sampling_params.html#samplingparams"><span class="std std-ref">SamplingParams class</span></a>).</p></li>
<li><p>Add support for Container Device Interface (CDI) for container runtimes (e.g., docker, containerd, and crio) (see <a class="reference internal" href="../cloud_native_toolkit/container.html#container"><span class="std std-ref">Container Support</span></a>).</p></li>
</ul>
</section>
<section id="id3">
<h3>🚨 Breaking Changes<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The SDK 2025.2.0 cannot load artifacts built with 2025.1.x. Please use the artifact built with 2025.2.x, or rebuild the model again with the new SDK.</p></li>
<li><p>The <cite>furiosa</cite> group is no longer required to access NPU devices on Linux systems.</p></li>
</ul>
<p>Versions of components:</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 80.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package name</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>furiosa-compiler</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-driver-rngd</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-firmware-tools-rngd</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-firmware-image-rngd</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-pert-rngd</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-model-compressor</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-llm</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-llm-models</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-mlperf</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-mlperf-resources</p></td>
<td><p>4.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-native-compiler</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-native-runtime</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-feature-discovery</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-device-plugin</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-smi</p></td>
<td><p>2025.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-libsmi</p></td>
<td><p>2025.2.0</p></td>
</tr>
</tbody>
</table>
</div>
<hr></section>
</section>
<section id="furiosa-sdk-2025-1-0-beta1-2025-02-24">
<span id="release2025-1-0"></span><h2>Furiosa SDK 2025.1.0 Beta1 (2025-02-24)<a class="headerlink" href="#furiosa-sdk-2025-1-0-beta1-2025-02-24" title="Link to this heading">#</a></h2>
<p>2025.1.0 is the third major SDK release for RNGD. This release includes a lot of new features and significant
improvements, including significant LLM latency optimization, tool-calling support in Furiosa-LLM,
the device remapping support for container environment, command line tools improvements, and bug fixes.</p>
<p>Please refer to the <a class="reference internal" href="../get_started/upgrade_guide.html#upgradeguide"><span class="std std-ref">Upgrading FuriosaAI’s Software</span></a> section for instructions on
obtaining this update.</p>
<section id="release2025-1-0-highlights">
<span id="id4"></span><h3>🚀 Highlights<a class="headerlink" href="#release2025-1-0-highlights" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>LLM Latency Optimization (Up to 11.66% TTFT, 11.45% TPOT improvement for 30k inputs, 1k outputs)</p></li>
<li><p>Support Tool-calling in Furiosa-LLM (<a class="reference external" href="https://developer.furiosa.ai/v2025.1.0/en/furiosa_llm/furiosa-llm-serve.html#tool-calling">Tool Calling</a>)</p></li>
<li><p>Support Device remapping (e.g., <code class="docutils literal notranslate"><span class="pre">/dev/rngd/npu2pe0-3</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">/dev/rngd/npu0pe0-3</span></code>) for container</p></li>
<li><p>Add the new command line tool <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">build</span></code> to build easily an artifact from Hugging Face model (<a class="reference external" href="https://developer.furiosa.ai/v2025.1.0/en/furiosa_llm/model-preparation-workflow.html#building-a-model-artifact">Building a Model Artifact</a>)</p></li>
<li><p>Fix continuous batch scheduling bugs which occur in certain ranges of sequence lengths and batch sizes</p></li>
<li><p>Automatic configuration of the maximum KV-cache memory allocation</p></li>
<li><p>Reduce fragmentation in runtime memory allocation</p></li>
<li><p>Allow <code class="docutils literal notranslate"><span class="pre">furiosa-mlperf</span></code> command to specify <code class="docutils literal notranslate"><span class="pre">pipeline_parallel_size</span></code> and <code class="docutils literal notranslate"><span class="pre">data_parallel_size</span></code></p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">--allowed-origins</span></code> argument to <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">serve</span></code> (<a class="reference external" href="https://developer.furiosa.ai/v2025.1.0/en/furiosa_llm/furiosa-llm-serve.html">OpenAIServer</a>)</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">trust_remote_code</span></code> support bug in furiosa-llm</p></li>
<li><p>Support Min-p sampling in <code class="docutils literal notranslate"><span class="pre">SamplingParams</span></code> (<a class="reference external" href="https://developer.furiosa.ai/v2025.1.0/en/furiosa_llm/reference/sampling_params.html">SamplingParams class</a>)</p></li>
<li><dl class="simple">
<dt>Allow <code class="docutils literal notranslate"><span class="pre">npu:X</span></code> in addition to <code class="docutils literal notranslate"><span class="pre">npu:X:*</span></code> in <code class="docutils literal notranslate"><span class="pre">devices</span></code> option</dt><dd><ul>
<li><p>e.g., <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">serve</span> <span class="pre">./model</span> <span class="pre">--devices</span> <span class="pre">&quot;npu:0&quot;</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">furiosa-mlperf</span></code> command supports <code class="docutils literal notranslate"><span class="pre">npu_queue_limit</span></code>, <code class="docutils literal notranslate"><span class="pre">spare_blocks_ratio</span></code>, allowing to optimize the performance</p></li>
</ul>
</section>
<section id="deprecations-upcoming-changes">
<h3>⚠️ Deprecations &amp; Upcoming Changes<a class="headerlink" href="#deprecations-upcoming-changes" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LLM.from_artifacts()</span></code> API will be deprecated from the 2025.2.0 release. Please use <code class="docutils literal notranslate"><span class="pre">LLM.load_artifact()</span></code> instead (<a class="reference external" href="https://developer.furiosa.ai/v2025.1.0/en/furiosa_llm/reference/llm.html">LLM class</a>).</p></li>
</ul>
</section>
<section id="id5">
<h3>🚨 Breaking Changes<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--model</span></code> option of <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">serve</span></code> become a positional argument.
Please use <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">serve</span> <span class="pre">&lt;model&gt;</span></code> instead of <code class="docutils literal notranslate"><span class="pre">furiosa-llm</span> <span class="pre">serve</span> <span class="pre">--model</span> <span class="pre">&lt;model&gt;</span></code>. (<a class="reference external" href="https://developer.furiosa.ai/v2025.1.0/en/furiosa_llm/furiosa-llm-serve.html">OpenAIServer</a>)</p></li>
</ul>
<p>Versions of components:</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 80.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package name</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>furiosa-compiler</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-driver-rngd</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-firmware-tools-rngd</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-firmware-image-rngd</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-pert-rngd</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-model-compressor</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-llm</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-llm-models</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-mlperf</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-mlperf-resources</p></td>
<td><p>4.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-native-compiler</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-native-runtime</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-feature-discovery</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-device-plugin</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-smi</p></td>
<td><p>2025.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-libsmi</p></td>
<td><p>2025.1.0</p></td>
</tr>
</tbody>
</table>
</div>
<hr></section>
</section>
<section id="furiosa-sdk-2024-2-1-beta0-2025-01-10">
<span id="release2024-2-1"></span><h2>Furiosa SDK 2024.2.1 Beta0 (2025-01-10)<a class="headerlink" href="#furiosa-sdk-2024-2-1-beta0-2025-01-10" title="Link to this heading">#</a></h2>
<p>2024.2.1 is a minor release based on 2024.2.0 major release.</p>
<p>Please refer to the <a class="reference internal" href="../get_started/upgrade_guide.html#upgradeguide"><span class="std std-ref">Upgrading FuriosaAI’s Software</span></a> section for instructions on
obtaining this update.</p>
<section id="release2024-2-1-highlights">
<span id="id7"></span><h3>🚀 Highlights<a class="headerlink" href="#release2024-2-1-highlights" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Support for context lengths of up to 32k in furiosa-llm for various models, including LLaMA 3.1, and EXAONE</p></li>
<li><p>Artifacts with the same <code class="docutils literal notranslate"><span class="pre">tensor_parallel_size</span></code> are compatible even with any <code class="docutils literal notranslate"><span class="pre">pipeline_parallel_size</span></code></p></li>
</ul>
<p>Versions of components:</p>
<div class="pst-scrollable-table-container"><table class="table">
<colgroup>
<col style="width: 80.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package name</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>furiosa-compiler</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-driver-rngd</p></td>
<td><p>2024.2.1</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-firmware-tools-rngd</p></td>
<td><p>2024.2.1</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-firmware-image-rngd</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-pert-rngd</p></td>
<td><p>2024.2.1</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-model-compressor</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-llm</p></td>
<td><p>2024.2.1</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-llm-models</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-mlperf</p></td>
<td><p>2024.2.1</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-mlperf-resources</p></td>
<td><p>4.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-native-compiler</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-native-runtime</p></td>
<td><p>2024.2.1</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-feature-discovery</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-device-plugin</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-smi</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-libsmi</p></td>
<td><p>2024.2.0</p></td>
</tr>
</tbody>
</table>
</div>
<hr></section>
</section>
<section id="furiosa-sdk-2024-2-0-beta0-2024-12-23">
<span id="release2024-2-0"></span><h2>Furiosa SDK 2024.2.0 Beta0 (2024-12-23)<a class="headerlink" href="#furiosa-sdk-2024-2-0-beta0-2024-12-23" title="Link to this heading">#</a></h2>
<p>2024.2.0 is the second major SDK release for RNGD.
This release includes a lot of new features and significant improvements,
including new model support, support for context lengths of up to 8k,
support for Tensor Parallelism, support for PyTorch 2.4, Optimum API, and
multiple performance improvements.</p>
<p>Please refer to the <a class="reference internal" href="../get_started/upgrade_guide.html#upgradeguide"><span class="std std-ref">Upgrading FuriosaAI’s Software</span></a> section for instructions on
obtaining this update.</p>
<section id="release2024-2-0-highlights">
<span id="id8"></span><h3>🚀 Highlights<a class="headerlink" href="#release2024-2-0-highlights" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>New Model support: Solar, EXAONE-3.0, CodeLLaMA2, Vicuna</p></li>
<li><p>Up to 8k context length support in models, such as LLaMA 3.1</p></li>
<li><p>Tensor Parallelism support (<code class="docutils literal notranslate"><span class="pre">tensor_parallel_size</span> <span class="pre">&lt;=</span> <span class="pre">8</span></code>)</p></li>
<li><p>PyTorch 2.4.1 support</p></li>
<li><p>Transformers 4.44.2 support</p></li>
<li><dl class="simple">
<dt>Furiosa-LLM</dt><dd><ul>
<li><dl class="simple">
<dt>ArtifactBuilder API and CLI tools (refer to <a class="reference external" href="https://developer.furiosa.ai/v2024.2.0/en/furiosa_llm/furiosa-llm-build.html#artifactbuilder">ArtifactBuilder</a>)</dt><dd><ul>
<li><p>Users can build artifacts from Huggingface Hub models with Huggingface Transformers compatible API</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Huggingface Transformers compatible API support (<cite>furiosa_llm.optimum</cite>)</dt><dd><ul>
<li><p>AutoModel, AutoModelForCausalLM, AutoModelForQuestionAnswering API</p></li>
<li><p>QuantizerForCausalLM API support for calibration and quantization</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>LLMEngine, AsyncLLMEngine API support compatible with vLLM</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>About 20% performance improvements in models based on LlamaForCausalLM</dt><dd><ul>
<li><p>e.g., 3580 tokens/sec in LLaMA 3.1 8B model with a single RNGD card</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="id9">
<h3>🚨 Breaking Changes<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>LLM.from_artifacts() API has been deprecated. Please use LLM.load_artifacts() instead.</p></li>
<li><p>The artifacts built from 2024.1.x is not compatible with 2024.2.x. Please use the artifact built from 2024.2.x.</p></li>
</ul>
<div class="pst-scrollable-table-container"><table class="table" id="id11">
<caption><span class="caption-text">Component version</span><a class="headerlink" href="#id11" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 80.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package name</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>furiosa-compiler</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-driver-rngd</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-firmware-tools-rngd</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-firmware-image-rngd</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-pert-rngd</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-llm</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-llm-models</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-mlperf</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-mlperf-resources</p></td>
<td><p>4.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-model-compressor</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-native-compiler</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-native-runtime</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-smi</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-libsmi</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-device-plugin</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-feature-discovery</p></td>
<td><p>2024.2.0</p></td>
</tr>
</tbody>
</table>
</div>
<hr></section>
</section>
<section id="furiosa-sdk-2024-1-0-alpha-2024-10-11">
<h2>Furiosa SDK 2024.1.0 Alpha (2024-10-11)<a class="headerlink" href="#furiosa-sdk-2024-1-0-alpha-2024-10-11" title="Link to this heading">#</a></h2>
<p>2024.1.0 is the first SDK release for RNGD. This release is alpha release,
and the features and APIs described in this document may change in the future.</p>
<section id="release2024-1-0-highlights">
<span id="id10"></span><h3>🚀 Highlights<a class="headerlink" href="#release2024-1-0-highlights" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Model Support: LLaMA 3.1 8B/70B, BERT Large, GPT-J 6B</p></li>
<li><dl class="simple">
<dt>Furiosa Quantizer supports the following quantization methods:</dt><dd><ul>
<li><p>BF16 (W16A16)</p></li>
<li><p>INT8 Weight-Only (W8A16)</p></li>
<li><p>FP8 (W8A8)</p></li>
<li><p>INT8 SmoothQuant (W8A8)</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Furiosa-LLM</dt><dd><ul>
<li><p>Efficient KV cache management with PagedAttention</p></li>
<li><p>Continuous batching support in serving</p></li>
<li><p>OpenAI-compatible API server</p></li>
<li><p>Greedy search and beam search</p></li>
<li><p>Pipeline Parallelism and Data Parallelism across multiple NPUs</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">furiosa-mlperf</span></code> command</dt><dd><ul>
<li><p>Server and Offline scenarios</p></li>
<li><p>BERT, GPT-J, LLaMA 3.1 benchmarks</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>System Management Interface</dt><dd><ul>
<li><p>System Management Interface Library and CLI for Furiosa NPU family</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Cloud Native Toolkit</dt><dd><ul>
<li><p>Kubernetes integration for managing and monitoring the Furiosa NPU family</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="pst-scrollable-table-container"><table class="table" id="id12">
<caption><span class="caption-text">Component version</span><a class="headerlink" href="#id12" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 80.0%" />
<col style="width: 20.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package name</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>furiosa-compiler</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-device-plugin</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-driver-rngd</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-feature-discovery</p></td>
<td><p>2024.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-firmware-tools-rngd</p></td>
<td><p>2024.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-firmware-image-rngd</p></td>
<td><p>2024.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-libsmi</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-llm</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-llm-models</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-mlperf</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-mlperf-resources</p></td>
<td><p>4.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-model-compressor</p></td>
<td><p>2024.1.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-native-compiler</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>furiosa-native-runtime</p></td>
<td><p>2024.2.0</p></td>
</tr>
<tr class="row-even"><td><p>furiosa-smi</p></td>
<td><p>2024.1.0</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../overview/supported_models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Supported Models</p>
      </div>
    </a>
    <a class="right-next"
       href="../overview/roadmap.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Roadmap</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> 
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2025-3-0-beta3-2025-08-04">Furiosa SDK 2025.3.0 Beta3 (2025-08-04)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#highlights">🚀 Highlights</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#major-features-improvements">Major Features &amp; Improvements</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-highlights">Performance Highlights</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#expanded-model-support">Expanded Model Support</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#breaking-changes">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2025-2-0-beta2-2025-04-25">Furiosa SDK 2025.2.0 Beta2 (2025-04-25)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2025-2-0-highlights">🚀 Highlights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2025-1-0-beta1-2025-02-24">Furiosa SDK 2025.1.0 Beta1 (2025-02-24)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2025-1-0-highlights">🚀 Highlights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deprecations-upcoming-changes">⚠️ Deprecations &amp; Upcoming Changes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2024-2-1-beta0-2025-01-10">Furiosa SDK 2024.2.1 Beta0 (2025-01-10)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2024-2-1-highlights">🚀 Highlights</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2024-2-0-beta0-2024-12-23">Furiosa SDK 2024.2.0 Beta0 (2024-12-23)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2024-2-0-highlights">🚀 Highlights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">🚨 Breaking Changes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#furiosa-sdk-2024-1-0-alpha-2024-10-11">Furiosa SDK 2024.1.0 Alpha (2024-10-11)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#release2024-1-0-highlights">🚀 Highlights</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By FuriosaAI, Inc.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025 FuriosaAI Inc.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>