.. _Roadmap:

==================================================
Roadmap
==================================================

FuriosaAI regularly publishes its software with new features, performance improvements, and expanded hardware support.
This page shows the forward-looking roadmap of ongoing & upcoming projects and when they are expected to land, broken down by areas on
:ref:`our software stack <SoftwareStack>`.

.. note::
    The latest release is |release|. You can find the release notes :ref:`here <WhatsNew>`.

Upcoming Releases 2026 Q1
==========================================
* ðŸ”¨ Qwen3 MoE, GPT-OSS, K-EXAONE model support
* ðŸ”¨ Qwen3 VL and multi-modal model support
* ðŸ”¨ KV cache offloading support
* ðŸ”¨ OpenAI Response format support
* ðŸ”¨ Speculative decoding support
* ðŸ”¨ PyTorch eager mode support

------------

2025 Q3 - Q4
==========================================

Furiosa-LLM
------------------------------------------
* âœ… Hybrid batching support (i.e., chunked prefill or inflight-batching)
* âœ… Exaone4, Qwen3 support
* âœ… Guided-decoding support (libguidance, xgrammar backends)
* âœ… Tool-calling support
* âœ… Prefix-caching support
* âœ… Pooling Model support (embedding, score, and rank)
* âœ… Fine-tuned model support
* âœ… Tensor Parallelism support Phase 2: Inter-chip
* âœ… Hugging Face Hub support
* âœ… Pre-compiled artifacts on Hugging Face Hub
* âœ… Qwen2 and Qwen2.5 model support
* âœ… EXAONE3 model support
* âœ… API Key based authentication support
* âœ… Harmony response format support

Quantization
------------------------------------------
* âœ… Fine-grained FP8 Quantization (dynamic quantization, mixed quantization)

Distributed & Scalable Inference
------------------------------------------
* âœ… llm-d integration
* âœ… NPU operator support for Kubernetes
* âœ… DRA (Dynamic Resource Allocation) support for Kubernetes


2025 Q1 - Q2
==========================================
* âœ… Tool-calling support in Furiosa-LLM (2025.1.0 release)
* âœ… Device remapping support (e.g., /dev/rngd/npu2pe0-3 -> /dev/rngd/npu0pe0-3) for container (2025.1.0 release)
* âœ… Automatic configuration for the maximum KV-cache memory allocation (2025.1.0 release)
* âœ… Min-p sampling support (2025.1.0 release)
* âœ… Chunked Prefill support in Furiosa-LLM (planned for 2025.2.0 release)
* âœ… Chat API support in Furiosa-LLM (planned for 2025.2.0 release)
* âœ… Reasoning parser support (2025.2.0 release)
* âœ… Torch 2.5.1 support (2025.2.0 release)
* âœ… Python 3.11 and 3.12 support (2025.2.0 release)
* âœ… Support for building bfloat16, float16, and float32 models to model artifact without quantization (2025.2.0 release)
* âœ… Metrics endpoint (``/metrics/``) support in Furiosa-LLM (2025.2.0 release)
* âœ… Model artifact support in Huggingface Hub (2025.2.0 release)
* âœ… Sampling parameter "logprobs" support (2025.2.0 release)
* âœ… Container Runtime and Container Interface Device (CDI) support (2025.2.0 release)

2024 Q4
==========================================
* âœ… Language Model Support: CodeLLaMA2, Vicuna, Solar, EXAONE-3.0 (2024.2.0 release)
* âœ… Vision Model Support: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, etc (2024.2.0 release)
* âœ… Tensor Parallelism support Phase 1: Intra-chip (2024.2.0 release)
* âœ… Torch 2.4.1 support (2024.2.0)
* âœ… Huggingface Optimum integration (2024.2.0 release)
